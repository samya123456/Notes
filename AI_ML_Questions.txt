1) Machine Learning: Automated Analytical model
2) Neural Network: A Type of machine learning Architecture modeled after biological neurons.
3) Deep Learning: A Neural Network with more than one hidden layer.

4) Overfitting:
when your Model touches every single point of your training data, your error is really low in the training set. but it doesn't create a good prediction model as it doesn't fall under any mathematical equation y = f(x). that's why we get an error large in the validation set or in the test set. this is called Overfitting i.e. fitting too much to the noise data.


Overcome Overfitting
Early stopping. Early stopping pauses the training phase before the machine learning model learns the noise in the data.
Pruning. You might identify several features or parameters that impact the final prediction when you build a model. ...

5) Good Model should look like having large errors at the beginning and errors will reduce over training a period of time.
6) Epochs: 1 epoch is running the entire training data 1 time through your model.

Model Evaluation Matrix: Classification Problem
================================================
  i) Accuracy = number of correct predictions / total number of predictions.
  ii) Recall = number of true positive / (number of true positive + number of false negative)
  iii) Precision = number of true positive / (number of true positive + number of false positive)
  iv) f1 Score = combination of Recall and Precision  matrix = 2*(Recall * Precision) / (Recall + Precision)

True positive: the pic is of the Dog and the model predicted it as Dog.
True Negative: the pic is not of the Dog and the model predicted it's not a Dog.
False positive: the pic is not of the Dog and the model predicted it's a Dog.
False Negative: the pic is of the Dog and the model predicted it's not a Dog.

Confusion Matrix:  We can Organise our predicted values compared to the real values in the Cofusion matrix

Model Evaluation Matrix: Regression Problem
===============================================
A linear Regression Problem is when your model is continuously predicting the result of a problem

 i) Mean Square Error
 ii) Mean Square Error
 iii) Root Mean Square Error


Unsupervised Learning
====================
Dealing with unlabeled data.

Tasks in unsupervised Learning:
==============================
i) Clustering - Grouping together unlabeled data points into clusters based on similarity
ii) Anomaly Detection - Attempt to detect outliers (Exceptions) in the dataset
iii) dimensionality reduction


Difference between supervised learning and Unsupervised learning stages: Only difference is that we don't split the dataset into Train and Test datasets in Unsupervised learning as the data is unlabeled. 


Percepron Model
===============


Single Biological Neuron ---> Percepron ---> Multi-Layer Perceptron Model ---> Deep learning Neural network

y = f(x) = x1*w1 + x2*w2 ; but if x1 or x2 =0 then that input will not be having any impact in the output. To fix that we add b.

y = f(x) = (x1*w1 + b) + (x2*w2 + b)

Neural network
==============

1st layer => input layer
last layer => output layer
middle layers => hidden layer


Activation Functions
====================

y = f(x) = x*w + b 

w = weight 
b = bias

if you want to set a boundary to the output 

z = x*w + b 

and we pass z in some activation function to limit the value

if we are doing a binary classification problem the output will be 0 or 1.
When we are doing Binary classification problems there are the Activation function functions used: 
https://ibm-learning.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp/learn/lecture/16844498#overview

	 A) Sigmoid function: 
	 ====================
	 
	 f(z) = 1/ (1 + e^(-z))
	 the output value will be 0 to 1
	 
	 B) Hyperbolic Tangent: 
	 ======================
	 
	 f(z) = tanh(z)
	 the output value will be -1 to 1
	 
	 C) Rectified linear unit: (most used Activation funcion)
	 =========================
	 f(z) = max(0 , z) , if value is > 0 then 0 else z
 
 
When we are doing Multi-class  classification problems there are the Activation function functions used: 
https://ibm-learning.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp/learn/lecture/16844504#overview

 ** in multi-class classification problem we are 2 situations
 i) Non-Exclusive classes: A data point can have multiple classes/categories assigned to it.
   Ex - photos can have multiple tags, beach, family vacations, etc.
   
   
 ii) Mutually Exclusive classes:
   Ex - Photos in grayscale can be categorized as black n white or full color
   
 
To organize data for  Multi-class  classification problems  we use one-hot encoding

 Non Exclusive Multi-class  classification problems Activation function :
	 A) Sigmoid function: 
	 ====================
	 
	 f(z) = 1/ (1 + e^(-z))
	 the output value will be 0 to 1
 Mutually Exclusive classes classification problems Activation function :
 
     A) SoftMax activation function:
	 ==============================
	 This function will calculate the probability of each target class, over all possible target classes.	
	 this probability will range between 0 to 1.
	 
	 this model returns the probabilities of each class and the target class will be chosen will have the highest probability.
	 
	 Example :
	  Red = 0.1
	  Green = 0.6
	  Blue = 0.3
	  
	  probablity sum =1
	  
	  so in this case we'll choose the target class as green as it has the highest probability
	  
	

Cost Function:
==============	
https://ibm-learning.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp/learn/lecture/16844516#overview



*Cost Function tells you how far you are from the true value based on your prediction.

*It Compares Our Neural Network with the true Value we use the cost function or loss function or error function.

 Here :
 =====
 y = true value 
 a = neural predictions
 
 Commonly used Cost function:
 ============================
 
 A) Quadratic Cost Function: Which essentially means root mean square error
 
 The cost function consists of four main things :
 W = weight
 B = Bias
 Sr = input of a single training sample
 Er = desired output










INTERVIEW QUESTIONS:
1) what is embedding
2) How chatGPT supports local languages although there is so low data set to train a model. --> First, ChatGPT uses its language-processing features to identify the language youâ€™ve used in your question/prompt. It uses natural language processing (NLP) techniques to understand the intent and emotion behind the text.

optimization
rule based algo -- mean square error , root mean square error
pysprak ***
databricks
=================
deploy model
issues faced different with data , when the data looks good but they are not really that good




Model optimization:
===================

Model optimization in TensorFlow involves a set of techniques aimed at improving the performance, efficiency, and generalization of your machine learning models. There are various approaches to optimizing TensorFlow models

1) Data Preprocessing: Ensuring that your input data is appropriately prepared can have a significant impact on model performance. Techniques like
    i) normalization
    ii) feature scaling
    iii) handling missing values are crucial steps to consider.

2) Choosing the Right Architecture: Choosing the right model is important.
3) Transfer Learning: For certain tasks, using pre-trained models and fine-tuning them on your specific dataset can be more efficient than training from scratch.
4) Pruning: Pruning involves removing insignificant weights from the model, leading to a more compact model with potential speed-up during inference.


Issues faced with data when the data looks good but they are not really that good :
=================================================================================
If your data appears to be of good quality, but your model's performance is not as good as expected, there could be several reasons for this discrepancy. Here are some steps to investigate and improve the situation:

	i) Data Exploration and Visualization: Revisit your data exploration process to ensure you haven't missed any important patterns or insights. Visualize the data in different ways to get a better understanding of its characteristics and potential issues.

	ii) Data Preprocessing: Check if your data preprocessing steps are appropriate. Ensure that you are
		1) handling missing values, 
                2) scaling features, and applying any necessary transformations correctly. 
	Incorrect preprocessing can lead to suboptimal model performance.

	iii) Feature Engineering: Evaluate if you have captured all the relevant features from your data. Sometimes, domain knowledge and creative feature engineering can significantly improve model performance.


Rule-Based Algorithms in Machine Learning:
==========================================

Rule-based algorithms are a class of machine learning approaches that rely on predefined rules or logical conditions to make predictions or decisions. Unlike traditional machine learning algorithms that learn patterns from data, rule-based algorithms are based on explicit rules set by domain experts or through manual analysis. These rules are often represented in the form of "if-then" statements or logical expressions.


MLOPS:
=======

1) Export a model:
================
https://www.youtube.com/watch?v=NVY0FucNRU4
  i) save the whole model (in HDF5 format)
     model.save("nn.h5")

2) Import a model from file:
============================
https://www.youtube.com/watch?v=NVY0FucNRU4

  i) model = keras.models.load_model("nn.h5")
